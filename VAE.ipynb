{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cst0313/Machine-Learning/blob/main/VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQG2iHUXhmrO",
        "outputId": "5407614b-5af4-4138-c1ea-a139d895c2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from PIL import Image\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets,layers,optimizers,Sequential,metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYgW1T3ncWn",
        "outputId": "7eb3447a-f424-4b4e-c788-0893fb3959ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2X5TUjRhnPQ"
      },
      "source": [
        "def save_img(imgs,names):\n",
        "  img_new = Image.new('L',(280,280))\n",
        "  index = 0\n",
        "  for i in range(0,280,80):\n",
        "    for j in range(0,280,80):\n",
        "      img = imgs[index]\n",
        "      img = Image.fromarray(img,mode='L')\n",
        "      img_new.paste(img,(i,j))\n",
        "      index+=1\n",
        "  img_new.save(names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8sUeQK7hsVv"
      },
      "source": [
        "def feature_scale(x):\n",
        "  x = tf.cast(x,dtype=tf.float32)/255.\n",
        "#  y = tf.cast(y,dtype=tf.int32)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTD-IP8Vhtog"
      },
      "source": [
        "#Dim reduct nums\n",
        "dim_reduce = 10\n",
        "batch_num = 128\n",
        "lr = 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti2IpZx5hvE3",
        "outputId": "37f62044-427e-4243-949c-39be718a72c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "(x,y),(x_test,y_test) = datasets.fashion_mnist.load_data()\n",
        "data = tf.data.Dataset.from_tensor_slices(x)\n",
        "data = data.map(feature_scale).shuffle(10000).batch(128)\n",
        "\n",
        "data_test = tf.data.Dataset.from_tensor_slices(x_test)\n",
        "data_test = data_test.map(feature_scale).batch(128)\n",
        "\n",
        "data_iter = iter(data)\n",
        "samples = next(data_iter)\n",
        "print(samples[0].shape,samples[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "(28, 28) (28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6TcYHYZhwLY"
      },
      "source": [
        "class VAE(keras.Model):\n",
        "  def __init__(self):\n",
        "    super(VAE,self).__init__()\n",
        "    #encoder\n",
        "    self.fc_layer_1 = layers.Dense(128)\n",
        "    self.fc_layer_2 = layers.Dense(dim_reduce)\n",
        "    self.fc_layer_3 = layers.Dense(dim_reduce)\n",
        "    \n",
        "    \n",
        "    self.fc_layer_4 = layers.Dense(128)\n",
        "    self.fc_layer_5 = layers.Dense(784)\n",
        "    \n",
        "\n",
        "  def model_encoder(self, x):\n",
        "    h = tf.nn.relu(self.fc_layer_1(x))\n",
        "    mean_fc = self.fc_layer_2(h)\n",
        "    var_fc = self.fc_layer_3(h)\n",
        "    return mean_fc,var_fc\n",
        "\n",
        "  def model_decoder(self, z):\n",
        "    out = tf.nn.relu(self.fc_layer_4(z))\n",
        "    out = self.fc_layer_5(out)\n",
        "    return out\n",
        "\n",
        "  def reparameter(self,mean_x,var_x):\n",
        "    eps = tf.random.normal(var_x.shape)\n",
        "    std = tf.exp(var_x)**0.5\n",
        "    z = mean_x + std*eps\n",
        "    return z\n",
        "  \n",
        "  def call(self, inputs, training=None):\n",
        "    mean_x,var_x = self.model_encoder(inputs)\n",
        "    z = self.reparameter(mean_x,var_x)\n",
        "    x = self.model_decoder(z)\n",
        "    return x,mean_x,var_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq5iRjgBk_vC",
        "outputId": "6eaf1766-eda2-47eb-fec1-84d46ec5c764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = VAE()\n",
        "model.build(input_shape=(4,784))\n",
        "optimizer = optimizers.Adam(lr=lr)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vae\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                multiple                  100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  1290      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  1290      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  1408      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  101136    \n",
            "=================================================================\n",
            "Total params: 205,604\n",
            "Trainable params: 205,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A9n0bWWxxGi"
      },
      "source": [
        "!rm -rf img_result\n",
        "!mkdir img_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJVDuQGllAld",
        "outputId": "7645a62f-bd6c-4aa1-f11d-a47a31d5b044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "optimizer = optimizers.Adam(lr=lr)\n",
        "for i in range(10):\n",
        "  for step,x in enumerate(data):\n",
        "    x = tf.reshape(x,[-1,784])\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits,mean_x,var_x = model(x)\n",
        "      loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x,logits=logits)\n",
        "      loss = tf.reduce_sum(loss)/x.shape[0]\n",
        "      kl_div = -0.5*(var_x+1-mean_x**2-tf.exp(var_x))\n",
        "      kl_div = tf.reduce_sum(kl_div)/x.shape[0]\n",
        "      \n",
        "      loss = loss + 1.*kl_div\n",
        "    grads = tape.gradient(loss,model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
        "    \n",
        "    if step %100==0:\n",
        "      print(i,step,'loss:',float(loss),'kl_div:',float(kl_div))\n",
        "      \n",
        "  x = next(iter(data_test))\n",
        "  val_x = tf.reshape(x,[-1,784])\n",
        "  logits,_,_ = model(val_x)\n",
        "  x_hat = tf.sigmoid(logits)\n",
        "  x_hat = tf.reshape(x_hat,[-1,28,28])\n",
        "  x_hat = x_hat.numpy()*255\n",
        "  x_hat = x_hat.astype(np.uint8)\n",
        "  save_img(x_hat,'img_result/AE_img_%d.png'%i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.0.0-rc2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "0 0 loss: 550.0194091796875 kl_div: 2.982800006866455\n",
            "0 100 loss: 318.5977478027344 kl_div: 14.45425033569336\n",
            "0 200 loss: 286.05633544921875 kl_div: 15.682866096496582\n",
            "0 300 loss: 279.5198669433594 kl_div: 14.796915054321289\n",
            "0 400 loss: 280.6016540527344 kl_div: 14.736173629760742\n",
            "1 0 loss: 257.4814147949219 kl_div: 14.586556434631348\n",
            "1 100 loss: 269.65826416015625 kl_div: 14.280157089233398\n",
            "1 200 loss: 268.595703125 kl_div: 14.174423217773438\n",
            "1 300 loss: 256.509033203125 kl_div: 14.179293632507324\n",
            "1 400 loss: 259.63641357421875 kl_div: 14.387566566467285\n",
            "2 0 loss: 246.9785919189453 kl_div: 14.598108291625977\n",
            "2 100 loss: 258.3591003417969 kl_div: 13.91586685180664\n",
            "2 200 loss: 251.0144805908203 kl_div: 14.502824783325195\n",
            "2 300 loss: 257.724365234375 kl_div: 14.840630531311035\n",
            "2 400 loss: 258.46173095703125 kl_div: 14.786937713623047\n",
            "3 0 loss: 246.58010864257812 kl_div: 15.479896545410156\n",
            "3 100 loss: 257.07232666015625 kl_div: 14.512933731079102\n",
            "3 200 loss: 253.34750366210938 kl_div: 15.150725364685059\n",
            "3 300 loss: 262.8245849609375 kl_div: 14.29986572265625\n",
            "3 400 loss: 247.87899780273438 kl_div: 14.056150436401367\n",
            "4 0 loss: 250.55979919433594 kl_div: 14.605419158935547\n",
            "4 100 loss: 258.7725830078125 kl_div: 14.367103576660156\n",
            "4 200 loss: 242.57484436035156 kl_div: 15.233071327209473\n",
            "4 300 loss: 265.15869140625 kl_div: 15.15379810333252\n",
            "4 400 loss: 257.04046630859375 kl_div: 15.23748779296875\n",
            "5 0 loss: 254.13113403320312 kl_div: 14.923895835876465\n",
            "5 100 loss: 249.06382751464844 kl_div: 14.930919647216797\n",
            "5 200 loss: 245.55953979492188 kl_div: 14.408332824707031\n",
            "5 300 loss: 258.4816589355469 kl_div: 14.470882415771484\n",
            "5 400 loss: 248.99795532226562 kl_div: 14.635311126708984\n",
            "6 0 loss: 252.57498168945312 kl_div: 14.992399215698242\n",
            "6 100 loss: 241.426513671875 kl_div: 14.589839935302734\n",
            "6 200 loss: 244.91261291503906 kl_div: 14.78602409362793\n",
            "6 300 loss: 242.66021728515625 kl_div: 15.219017028808594\n",
            "6 400 loss: 244.71995544433594 kl_div: 14.797220230102539\n",
            "7 0 loss: 250.021240234375 kl_div: 13.908668518066406\n",
            "7 100 loss: 254.02186584472656 kl_div: 14.979219436645508\n",
            "7 200 loss: 253.0924835205078 kl_div: 15.560726165771484\n",
            "7 300 loss: 258.694091796875 kl_div: 14.99019718170166\n",
            "7 400 loss: 243.21836853027344 kl_div: 14.744919776916504\n",
            "8 0 loss: 262.965576171875 kl_div: 16.113204956054688\n",
            "8 100 loss: 239.51248168945312 kl_div: 14.702247619628906\n",
            "8 200 loss: 239.82687377929688 kl_div: 14.765560150146484\n",
            "8 300 loss: 237.31752014160156 kl_div: 14.668912887573242\n",
            "8 400 loss: 247.21676635742188 kl_div: 13.768196105957031\n",
            "9 0 loss: 239.25079345703125 kl_div: 14.377815246582031\n",
            "9 100 loss: 241.92233276367188 kl_div: 15.032740592956543\n",
            "9 200 loss: 254.67385864257812 kl_div: 14.645343780517578\n",
            "9 300 loss: 245.84036254882812 kl_div: 14.684002876281738\n",
            "9 400 loss: 243.9701690673828 kl_div: 14.426889419555664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1gw0Ar1xv-B"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('img_result/AE_img_9.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yArSLqiWmq7p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}